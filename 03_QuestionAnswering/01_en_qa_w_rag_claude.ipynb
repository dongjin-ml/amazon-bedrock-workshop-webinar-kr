{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Question & Answering with Amazon Bedrock using LangChain\n",
    "\n",
    "> *This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context\n",
    "이전에는 모델이 타이어 교체 방법을 알려주는 것을 보았지만 관련 데이터를 수동으로 제공하고 컨텍스트를 직접 제공해야 했습니다. 우리는 Bedrock에서 사용할 수 있는 모델을 활용하고 교육 중에 학습한 지식과 수동 컨텍스트 제공을 기반으로 질문하는 접근 방식을 탐색했습니다. 이러한 접근 방식은 짧은 문서나 단일 톤 애플리케이션에서는 작동하지만, 모델에 전송된 프롬프트에 모두 들어맞을 수 없는 대규모 기업 문서가 있을 수 있는 기업 수준의 질문 응답으로 확장되지 않습니다. \n",
    "\n",
    "### Pattern\n",
    "RAG(검색 증강 생성)라는 아키텍처를 구현하여 이 프로세스를 개선할 수 있습니다. RAG는 언어 모델 외부(비모수적)에서 데이터를 검색하고 검색된 관련 데이터를 컨텍스트에 추가하여 프롬프트를 강화합니다.\n",
    "\n",
    "이 노트에서는 질문 응답 패턴에 접근하여 문서를 찾고 활용하여 사용자 질문에 대한 답변을 제공하는 방법을 설명합니다.\n",
    "\n",
    "### Challenges\n",
    "- 토큰 한도를 초과하는 대용량 문서 관리 방법\n",
    "- 질문과 관련된 문서를 찾는 방법\n",
    "\n",
    "### Proposal\n",
    "위의 과제에 대해 본 노트북에서는 다음과 같은 전략을 제안합니다.\n",
    "\n",
    "#### Prepare documents\n",
    "![Embeddings](./images/Embeddings_lang.png)\n",
    "\n",
    "질문에 답하기 전에 문서를 처리하고 문서 chunk 색인에 저장해야 합니다.\n",
    "- 문서를 로드\n",
    "- 더 작은 청크(chunk)로 처리하고 분할합니다.\n",
    "- Amazon Bedrock Titan Embeddings 모델을 사용하여 각 청크의 수치 벡터 표현 생성\n",
    "- 청크와 해당 임베딩을 사용하여 인덱스 생성\n",
    "\n",
    "#### Ask question\n",
    "![Question](./images/Chatbot_lang.png)\n",
    "\n",
    "문서 색인이 준비되면 질문할 준비가 된 것이며, 질문한 질문에 따라 관련 문서를 가져옵니다. 다음 단계가 실행됩니다.\n",
    "- 입력 질문의 임베딩 생성\n",
    "- 질문 임베딩과 인덱스의 임베딩을 비교합니다.\n",
    "- (상위 N) 관련 문서 청크를 가져옵니다.\n",
    "- 프롬프트에서 컨텍스트의 일부로 해당 청크를 추가합니다.\n",
    "- Amazon Bedrock의 모델에 프롬프트를 보냅니다.\n",
    "- 검색된 문서를 기반으로 상황에 맞는 답변을 얻습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usecase\n",
    "#### Dataset\n",
    "이 아키텍처 패턴을 설명하기 위해 IRS의 문서를 사용합니다. 이 문서에서는 다음과 같은 주제를 설명합니다:\n",
    "- OID(원래 발행 할인) 상품\n",
    "- $10,000 이상의 현금 지급을 IRS에 신고\n",
    "- 고용주 세금 안내\n",
    "\n",
    "#### Persona\n",
    "IRS의 작동 방식과 일부 조치가 영향을 미치는지 여부를 이해하지 못하는 일반인의 페르소나를 가정해 보겠습니다.\n",
    "\n",
    "모델은 문서를 바탕으로 쉬운 언어로 답변하려고 노력할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "RAG 접근 방식을 따르기 위해 이 노트북은 RAG와 같은 패턴을 효율적으로 구축할 수 있는 다양한 서비스 및 도구와 통합된 LangChain 프레임워크를 사용하고 있습니다. 우리는 다음 도구를 사용할 것입니다:\n",
    "\n",
    "- **LLM (Large Language Model)**: Anthropic Claude V1 available through Amazon Bedrock\n",
    "\n",
    "  이 모델은 문서 청크(chunk)를 이해하고 인간 친화적인 방식으로 답변을 제공하는 데 사용됩니다.\n",
    "- **Embeddings Model**: Amazon Titan Embeddings available through Amazon Bedrock\n",
    "\n",
    "  이 모델은 텍스트 문서의 수치 표현을 생성하는 데 사용됩니다.\n",
    "- **Document Loader**: PDF Loader available through LangChain\n",
    "\n",
    "  이는 소스에서 문서를 로드할 수 있는 로더입니다. 이 노트북을 위해 로컬 경로에서 샘플 파일을 로드합니다. 이는 기업 내부 시스템에서 문서를 로드하는 로더로 쉽게 대체될 수 있습니다.\n",
    "\n",
    "- **Vector Store**: FAISS available through LangChain\n",
    "\n",
    "  이 노트북에서는 이 메모리 내 벡터 chunk를 사용하여 임베딩과 문서를 모두 저장합니다. 엔터프라이즈 환경에서는 이는 AWS OpenSearch, pgVector가 포함된 RDS Postgres, ChromaDB, Pinecone 또는 Weaviate와 같은 영구 chunk로 대체될 수 있습니다.\n",
    "\n",
    "- **Index**: VectorIndex\n",
    "\n",
    "  인덱스는 입력 임베딩과 문서 임베딩을 비교하여 관련 문서를 찾는 데 도움이 됩니다.\n",
    "- **Wrapper**: 인덱스, 벡터 chunk, 임베딩 모델 및 LLM을 래핑하여 사용자로부터 논리를 추상화합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "이 노트북의 나머지 부분을 실행하기 전에 아래 셀을 실행하여 (필요한 라이브러리가 설치되어 있는지 확인하고) Bedrock에 연결해야 합니다.\n",
    "\n",
    "설정 작동 방식과 ⚠️ **변경이 필요한지 여부**에 대한 자세한 내용은 [Bedrock boto3 setup notebook](../00_Intro/bedrock_boto3_setup.ipynb) 노트북을 참조하세요.\n",
    "\n",
    "이 노트북에는 몇 가지 추가 종속성도 필요합니다:\n",
    "\n",
    "- [FAISS](https://github.com/facebookresearch/faiss), to store vector embeddings\n",
    "- [PyPDF](https://pypi.org/project/pypdf/), for handling PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Requirement '../dependencies/awscli-*-py3-none-any.whl' looks like a filename, but the file does not exist\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Requirement '../dependencies/boto3-*-py3-none-any.whl' looks like a filename, but the file does not exist\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Requirement '../dependencies/botocore-*-py3-none-any.whl' looks like a filename, but the file does not exist\u001b[0m\u001b[33m\n",
      "\u001b[0mProcessing /root/amazon-bedrock-workshop-webinar-kr/dependencies/awscli-*-py3-none-any.whl\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/root/amazon-bedrock-workshop-webinar-kr/dependencies/awscli-*-py3-none-any.whl'\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you ran `download-dependencies.sh` from the root of the repository first!\n",
    "%pip install --no-build-isolation --force-reinstall \\\n",
    "    ../dependencies/awscli-*-py3-none-any.whl \\\n",
    "    ../dependencies/boto3-*-py3-none-any.whl \\\n",
    "    ../dependencies/botocore-*-py3-none-any.whl\n",
    "\n",
    "%pip install --quiet \"faiss-cpu>=1.7,<2\" langchain==0.0.249 \"pypdf>=3.8,<4\"\n",
    "# %pip install --quiet \"faiss-cpu>=1.7,<2\" langchain==0.0.292 \"pypdf>=3.8,<4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-east-1\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock(https://bedrock.us-east-1.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww\n",
    "\n",
    "\n",
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "# os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"https://bedrock.us-east-1.amazonaws.com\"  # E.g. \"https://...\"\n",
    "\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure langchain\n",
    "\n",
    "LLM 및 임베딩 모델을 인스턴스화하는 것부터 시작합니다. 여기서는 텍스트 생성을 위해 Anthropic Claude를 사용하고 텍스트 삽입을 위해 Amazon Titan을 사용합니다.\n",
    "\n",
    "참고: Bedrock과 함께 사용 가능한 다른 모델을 선택할 수도 있습니다. 모델을 변경하려면 다음과 같이 `model_id`를 교체하면 됩니다.\n",
    "\n",
    "`llm = Bedrock(model_id=\"amazon.titan-tg1-large\")`\n",
    "\n",
    "Available model IDs include:\n",
    "\n",
    "- `amazon.titan-tg1-large`\n",
    "- `ai21.j2-grande-instruct`\n",
    "- `ai21.j2-jumbo-instruct`\n",
    "- `anthropic.claude-instant-v1`\n",
    "- `anthropic.claude-v1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will be using the Titan Embeddings Model to generate our Embeddings.\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "# - create the Anthropic Model\n",
    "llm = Bedrock(model_id=\"anthropic.claude-v2\", client=boto3_bedrock, model_kwargs={'max_tokens_to_sample':1000})\n",
    "bedrock_embeddings = BedrockEmbeddings(client=boto3_bedrock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bedrock(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<botocore.client.Bedrock object at 0x7f4711824b80>, region_name=None, credentials_profile_name=None, model_id='anthropic.claude-v2', model_kwargs={'max_tokens_to_sample': 1000}, endpoint_url=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BedrockEmbeddings(client=<botocore.client.Bedrock object at 0x7f4711824b80>, region_name=None, credentials_profile_name=None, model_id='amazon.titan-e1t-medium', model_kwargs=None, endpoint_url=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "먼저 문서 저장소를 구축하기 위해 일부 파일을 다운로드해 보겠습니다. 이 예에서는 여기에서 공개 IRS 문서를 사용합니다.[here](https://www.irs.gov/publications)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "files = [\n",
    "    \"https://www.irs.gov/pub/irs-pdf/p1544.pdf\",\n",
    "    \"https://www.irs.gov/pub/irs-pdf/p15.pdf\",\n",
    "    \"https://www.irs.gov/pub/irs-pdf/p1212.pdf\",\n",
    "]\n",
    "for url in files:\n",
    "    file_path = os.path.join(\"data\", url.rpartition(\"/\")[2])\n",
    "    urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다운로드한 후 [DirectoryLoader from PyPDF available under LangChain](https://python.langchain.com/en/latest/reference/modules/document_loaders.html)를 사용하여 문서를 로드하고 더 작은 청크(chunk)로 나눌 수 있습니다.\n",
    "\n",
    "참고: 검색된 문서/텍스트는 질문에 대답하기에 충분한 정보를 포함할 만큼 커야 합니다. 하지만 LLM 프롬프트에 들어갈 만큼 충분히 작습니다. 또한 임베딩 모델에는 입력 토큰 길이가 512개 토큰으로 제한되어 있으며 이는 대략 2000자까지 변환됩니다. 이 사용 사례를 위해 우리는 [RecursiveCharacterTextSplitter](https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/recursive_text_splitter.html)를 사용하여 100자가 겹치는 대략 1000자의 청크를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"./data/\")\n",
    "\n",
    "documents = loader.load()\n",
    "# - in our testing Character split works better with this PDF data set\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 100,\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length among 73 documents loaded is 5844 characters.\n",
      "After the split we have 503 documents more than the original 73.\n",
      "Average length among 503 documents (after split) is 909 characters.\n"
     ]
    }
   ],
   "source": [
    "avg_doc_length = lambda documents: sum([len(doc.page_content) for doc in documents])//len(documents)\n",
    "avg_char_count_pre = avg_doc_length(documents)\n",
    "avg_char_count_post = avg_doc_length(docs)\n",
    "print(f'Average length among {len(documents)} documents loaded is {avg_char_count_pre} characters.')\n",
    "print(f'After the split we have {len(docs)} documents more than the original {len(documents)}.')\n",
    "print(f'Average length among {len(docs)} documents (after split) is {avg_char_count_post} characters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 3개의 PDF 문서를 500개 이하의 작은 청크(chunk)로 분할했습니다. \n",
    "\n",
    "이제 해당 청크 중 하나에 대한 샘플 임베딩이 어떻게 보이는지 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample embedding of a document chunk:  [-0.15917969  0.76171875  0.24511719 ...  0.12109375 -0.25585938\n",
      "  0.06591797]\n",
      "Size of the embedding:  (4096,)\n"
     ]
    }
   ],
   "source": [
    "sample_embedding = np.array(bedrock_embeddings.embed_query(docs[0].page_content))\n",
    "print(\"Sample embedding of a document chunk: \", sample_embedding)\n",
    "print(\"Size of the embedding: \", sample_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유사한 패턴에 따라 전체 코퍼스에 대해 임베딩을 생성하고 벡터 chunk에 저장할 수 있습니다. \n",
    "\n",
    "이는 임베딩 모델과 문서를 입력받아 전체 벡터 저장소를 생성하는 LangChain 내부의 [FAISS](https://github.com/facebookresearch/faiss)  구현을 사용하여 쉽게 수행할 수 있습니다. [LangChain](https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/faiss.html)를 사용하면 프롬프트 생성, 쿼리 임베딩 가져오기, 관련 문서 샘플링 및 LLM 호출과 같은 대부분의 무거운 작업을 추상화할 수 있습니다. [VectorStoreIndexWrapper](https://python.langchain.com/docs/modules/data_connection/retrievers)가 이를 도와줍니다.\n",
    "\n",
    "**⚠️⚠️⚠️ NOTE: it might take few minutes to run the following cell ⚠️⚠️⚠️**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "\n",
    "vectorstore_faiss = FAISS.from_documents(\n",
    "    docs,\n",
    "    bedrock_embeddings,\n",
    ")\n",
    "\n",
    "wrapper_store_faiss = VectorStoreIndexWrapper(vectorstore=vectorstore_faiss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering\n",
    "\n",
    "이제 벡터 저장소가 준비되었으므로 질문을 시작할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreIndexWrapper(vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x7f46f8287f10>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper_store_faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"Is it possible that I get sentenced to jail due to failure in filings?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 단계는 문서와 비교할 수 있도록 쿼리 임베딩을 만드는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11181641, -0.20019531,  0.00915527, ..., -0.4921875 ,\n",
       "       -0.05664062,  0.43359375])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embedding = vectorstore_faiss.embedding_function(query)\n",
    "np.array(query_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 쿼리 임베딩을 사용하여 관련 문서를 가져올 수 있습니다. 이제 쿼리는 임베딩으로 표시되어 가장 관련성이 높은 정보를 제공하는 데이터 저장소에 대해 쿼리의 유사성 검색을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 documents are fetched which are relevant to the query.\n",
      "----\n",
      "## Document 1: There are civil penalties for failure to:\n",
      "File a correct Form 8300 by the date it is\n",
      "due, and\n",
      "Provide the required statement to those\n",
      "named in the Form 8300.\n",
      "If you intentionally disregard the requirement\n",
      "to file a correct Form 8300 by the date it is due,\n",
      "the penalty is the greater of:\n",
      "1.$25,000, or\n",
      "2.The amount of cash you received and\n",
      "were required to report (up to $100,000).\n",
      "There are criminal penalties for:\n",
      "Willful failure to file Form 8300,\n",
      "Willfully filing a false or fraudulent Form\n",
      "8300,\n",
      "Stopping or trying to stop Form 8300 from\n",
      "being filed, and\n",
      "Setting up, helping to set up, or trying to\n",
      "set up a transaction in a way that would\n",
      "make it seem unnecessary to file Form\n",
      "8300.\n",
      "If you willfully fail to file Form 8300, you can\n",
      "be fined up to $250,000 for individuals\n",
      "RECORDS($500,000 for corporations) or sentenced to up\n",
      "to 5 years in prison, or both. These dollar\n",
      "amounts are based on Section 3571 of Title 18\n",
      "of the U.S. Code........\n",
      "---\n",
      "## Document 2: Page 31 of 49  Fileid: … ations/p15/2023/a/xml/cycle05/source 15:08 - 13-Dec-2022\n",
      "The type and rule above prints on all proofs including departmental reproduction proofs. MUST be\n",
      "removed before printing.Penalty Charged for... 2% Deposits made 1 to 5 days late.5% Deposits made 6\n",
      "to 15 days late.10% Deposits made 16 or more days late, but before 10 days from\n",
      "the date of the first notice the IRS sent asking for the tax due.10% Amounts that should have been\n",
      "deposited, but instead were\n",
      "paid directly to the IRS, or paid with your tax return. But see\n",
      "Payment with return , earlier in this section, for exceptions.15% Amounts still unpaid more than 10\n",
      "days after the date of the\n",
      "first notice the IRS sent asking for the tax due or the day on\n",
      "which you received notice and demand for immediate\n",
      "payment, whichever is earlier.\n",
      "Late deposit penalty amounts are determined using\n",
      "calendar days, starting from the due date of the liability.\n",
      "Special rule for former Form 944 filers.  If you filed.......\n",
      "---\n",
      "## Document 3: filed when required, there is a failure -to-file (FTF) penalty\n",
      "of 5% of the unpaid tax due with that return. The maximum\n",
      "penalty is generally 25% of the tax due. Also, for each\n",
      "whole or part month the tax is paid late, there is a fail-\n",
      "ure-to- pay (FTP) penalty of 0.5% per month of the amount\n",
      "of tax. For individual filers only, the FTP penalty is re-\n",
      "duced from 0.5% per month to 0.25% per month if an in-\n",
      "stallment agreement is in effect. You must have filed your\n",
      "return on or before the due date of the return to qualify for\n",
      "the reduced penalty. The maximum amount of the FTP\n",
      "penalty is also 25% of the tax due. If both penalties apply\n",
      "in any month, the FTF penalty is reduced by the amount of\n",
      "the FTP penalty. The penalties won't be charged if you\n",
      "have reasonable cause for failing to file or pay. If you re-\n",
      "ceive a penalty notice, you can provide an explanation of\n",
      "why you believe reasonable cause exists.\n",
      "Note.  In addition to any penalties, interest accrues.......\n",
      "---\n",
      "## Document 4: amounts are based on Section 3571 of Title 18\n",
      "of the U.S. Code.\n",
      "The penalties for failure to file may also ap-\n",
      "ply to any person (including a payer) who at-\n",
      "tempts to interfere with or prevent the seller (or\n",
      "business) from filing a correct Form 8300. This\n",
      "includes any attempt to structure the transac-\n",
      "tion in a way that would make it seem unneces-\n",
      "sary to file Form 8300. Structuring means\n",
      "breaking up a large cash transaction into small\n",
      "cash transactions.\n",
      "How To Get Tax Help\n",
      "Whether it's help with a tax issue, preparing\n",
      "your tax return or a need for a free publication\n",
      "or form, get the help you need the way you want\n",
      "it: online, use a smart phone, call or walk in to\n",
      "an IRS office or volunteer site near you.\n",
      "Free help with your tax return.  You can get\n",
      "free help preparing your return nationwide from\n",
      "IRS-certified volunteers. The Volunteer Income\n",
      "Tax Assistance (VITA) program helps\n",
      "low-to-moderate income, elderly, people with\n",
      "disabilities, and limited English proficient tax-.......\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "relevant_documents = vectorstore_faiss.similarity_search_by_vector(query_embedding)\n",
    "print(f'{len(relevant_documents)} documents are fetched which are relevant to the query.')\n",
    "print('----')\n",
    "for i, rel_doc in enumerate(relevant_documents):\n",
    "    print_ww(f'## Document {i+1}: {rel_doc.page_content}.......')\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 관련 문서가 있으므로 LLM을 사용하여 이러한 문서를 기반으로 답변을 생성할 차례입니다.\n",
    "\n",
    "유사성 검색 결과를 기반으로 검색된 관련 문서와 함께 초기 프롬프트를 사용합니다. 그런 다음 이를 결합하여 모델에 피드백하여 결과를 얻는 프롬프트를 생성합니다. 이 시점에서 우리 모델은 매뉴얼에 설명된 대로 특정 자동차의 타이어를 교체할 수 있는 방법에 대한 고도의 정보를 제공해야 합니다.\n",
    "\n",
    "LangChain은 이를 쉽게 수행할 수 있는 방법에 대한 추상화를 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick way\n",
    "Vector Store를 둘러싸서 LLM 입력을 받는 LangChain에서 제공하는 Wrapper를 사용할 수 있습니다. 이 Wrapper는 뒤에서 다음 단계를 수행합니다:\n",
    "- 질문을 입력\n",
    "- 질문 임베딩 생성\n",
    "- 관련 문서 가져오기\n",
    "- 프롬프트에 문서와 질문을 채워 넣습니다.\n",
    "- 프롬프트로 모델을 호출하고 사람이 읽을 수 있는 방식으로 답변을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Yes, there are criminal penalties for willful failure to file Form 8300, which can include fines of\n",
      "up to $250,000 and up to 5 years in prison for individuals. The penalties apply not just for failure\n",
      "to file, but also for filing a false or fraudulent form, obstructing the filing, or structuring\n",
      "transactions to avoid the filing requirement. So it is possible to receive a jail sentence for\n",
      "issues related to failure to properly file Form 8300.\n"
     ]
    }
   ],
   "source": [
    "answer = wrapper_store_faiss.query(question=query, llm=llm)\n",
    "print_ww(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ask a different question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_2 = \"What is the difference between market discount and qualified stated interest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The key differences between market discount and qualified stated interest on a debt instrument are:\n",
      "\n",
      "Market discount - This occurs when the adjusted basis of a debt instrument immediately after\n",
      "acquisition is less than its issue price plus accrued OID at that time. Market discount arises when\n",
      "the value of the debt instrument has decreased since original issue, usually due to an increase in\n",
      "market interest rates. The discount is the difference between the issue price plus accrued OID and\n",
      "the adjusted basis.\n",
      "\n",
      "Qualified stated interest - This is stated interest on a debt instrument that is unconditionally\n",
      "payable in cash at least annually over the term of the instrument at a single fixed rate. It is\n",
      "generally not treated as OID. Qualified stated interest is part of the stated redemption price at\n",
      "maturity used to determine the existence and amount of OID on the debt instrument.\n",
      "\n",
      "In summary:\n",
      "- Market discount is a discount to adjusted basis reflecting a decrease in value/increase in\n",
      "interest rates.\n",
      "- Qualified stated interest is part of the stated interest payments on a debt instrument that is\n",
      "excluded from the calculation of OID.\n"
     ]
    }
   ],
   "source": [
    "answer_2 = wrapper_store_faiss.query(question=query_2, llm=llm)\n",
    "print_ww(answer_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customisable option\n",
    "위 시나리오에서는 질문에 대한 상황 인식 답변을 빠르고 쉽게 얻을 수 있는 방법을 탐색했습니다. 이제 문서를 가져오는 방법을 사용자 정의할 수 있는 [RetrievalQA](https://python.langchain.com/en/latest/modules/chains/index_examples/Vector_db_qa.html)의 도움으로 더 사용자 정의 가능한 옵션을 살펴보겠습니다. `chain_type` 매개변수를 사용하여 프롬프트에 추가해야 합니다. 또한 검색해야 하는 관련 문서 수를 제어하려면 아래 셀에서 'k' 매개변수를 변경하여 다른 출력을 확인하세요. 많은 시나리오에서 LLM이 답변을 생성하는 데 사용한 소스 문서가 무엇인지 알고 싶을 수 있습니다. LLM 프롬프트의 컨텍스트에 추가된 문서를 반환하는 `return_source_documents`를 사용하여 출력에서 해당 문서를 가져올 수 있습니다. 'RetrievalQA'를 사용하면 모델에 특정한 사용자 정의 [프롬프트 템플릿](https://python.langchain.com/en/latest/modules/prompts/prompt_templates/getting_started.html)을 제공할 수도 있습니다.\n",
    "\n",
    "참고: 이 예에서는 Amazon Bedrock에서 LLM으로 Anthropic Claude를 사용하고 있습니다. 이 특정 모델은 입력이 `Human:` 아래에 제공되고 모델이 `Assistant:` 다음에 출력을 생성하도록 요청하는 경우 가장 잘 수행됩니다. 아래 셀에는 LLM이 고정 상태를 유지하고 컨텍스트 외부에서 응답하지 않도록 프롬프트를 제어하는 방법의 예가 나와 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the context provided, yes it is possible to be sentenced to jail for willful failure to\n",
      "file Form 8300. The passage states:\n",
      "\n",
      "\"There are criminal penalties for:\n",
      "- Willful failure to file Form 8300,\n",
      "- Willfully filing a false or fraudulent Form 8300,\n",
      "- Stopping or trying to stop Form 8300 from being filed, and\n",
      "- Setting up, helping to set up, or trying to set up a transaction in a way that would make it seem\n",
      "unnecessary to file Form 8300.\n",
      "\n",
      "If you willfully fail to file Form 8300, you can be fined up to $250,000 for individuals ($500,000\n",
      "for corporations) or sentenced to up to 5 years in prison, or both.\"\n",
      "\n",
      "So willful failure to file Form 8300 can result in fines and/or up to 5 years in prison.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Human: Use the following pieces of context to provide a concise answer to the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Assistant:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore_faiss.as_retriever(\n",
    "        search_type=\"similarity\", search_kwargs={\"k\": 3}\n",
    "    ),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")\n",
    "query = \"Is it possible that I get sentenced to jail due to failure in filings?\"\n",
    "result = qa({\"query\": query})\n",
    "print_ww(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "1. context to be fed into FM(e.g. Claude-v2)\n",
      "-----------------------------------------------\n",
      "There are civil penalties for failure to:\n",
      "File a correct Form 8300 by the date it is\n",
      "due, and\n",
      "Provide the required statement to those\n",
      "named in the Form 8300.\n",
      "If you intentionally disregard the requirement\n",
      "to file a correct Form 8300 by the date it is due,\n",
      "the penalty is the greater of:\n",
      "1.$25,000, or\n",
      "2.The amount of cash you received and\n",
      "were required to report (up to $100,000).\n",
      "There are criminal penalties for:\n",
      "Willful failure to file Form 8300,\n",
      "Willfully filing a false or fraudulent Form\n",
      "8300,\n",
      "Stopping or trying to stop Form 8300 from\n",
      "being filed, and\n",
      "Setting up, helping to set up, or trying to\n",
      "set up a transaction in a way that would\n",
      "make it seem unnecessary to file Form\n",
      "8300.\n",
      "If you willfully fail to file Form 8300, you can\n",
      "be fined up to $250,000 for individuals\n",
      "RECORDS($500,000 for corporations) or sentenced to up\n",
      "to 5 years in prison, or both. These dollar\n",
      "amounts are based on Section 3571 of Title 18\n",
      "of the U.S. Code.\n",
      "-----------------------------------------------\n",
      "2. context to be fed into FM(e.g. Claude-v2)\n",
      "-----------------------------------------------\n",
      "Page 31 of 49  Fileid: … ations/p15/2023/a/xml/cycle05/source 15:08 - 13-Dec-2022\n",
      "The type and rule above prints on all proofs including departmental reproduction proofs. MUST be\n",
      "removed before printing.Penalty Charged for... 2% Deposits made 1 to 5 days late.5% Deposits made 6\n",
      "to 15 days late.10% Deposits made 16 or more days late, but before 10 days from\n",
      "the date of the first notice the IRS sent asking for the tax due.10% Amounts that should have been\n",
      "deposited, but instead were\n",
      "paid directly to the IRS, or paid with your tax return. But see\n",
      "Payment with return , earlier in this section, for exceptions.15% Amounts still unpaid more than 10\n",
      "days after the date of the\n",
      "first notice the IRS sent asking for the tax due or the day on\n",
      "which you received notice and demand for immediate\n",
      "payment, whichever is earlier.\n",
      "Late deposit penalty amounts are determined using\n",
      "calendar days, starting from the due date of the liability.\n",
      "Special rule for former Form 944 filers.  If you filed\n",
      "-----------------------------------------------\n",
      "3. context to be fed into FM(e.g. Claude-v2)\n",
      "-----------------------------------------------\n",
      "filed when required, there is a failure -to-file (FTF) penalty\n",
      "of 5% of the unpaid tax due with that return. The maximum\n",
      "penalty is generally 25% of the tax due. Also, for each\n",
      "whole or part month the tax is paid late, there is a fail-\n",
      "ure-to- pay (FTP) penalty of 0.5% per month of the amount\n",
      "of tax. For individual filers only, the FTP penalty is re-\n",
      "duced from 0.5% per month to 0.25% per month if an in-\n",
      "stallment agreement is in effect. You must have filed your\n",
      "return on or before the due date of the return to qualify for\n",
      "the reduced penalty. The maximum amount of the FTP\n",
      "penalty is also 25% of the tax due. If both penalties apply\n",
      "in any month, the FTF penalty is reduced by the amount of\n",
      "the FTP penalty. The penalties won't be charged if you\n",
      "have reasonable cause for failing to file or pay. If you re-\n",
      "ceive a penalty notice, you can provide an explanation of\n",
      "why you believe reasonable cause exists.\n",
      "Note.  In addition to any penalties, interest accrues\n"
     ]
    }
   ],
   "source": [
    "def show_context_used(context_list):\n",
    "    for idx, context in enumerate(context_list):\n",
    "        print(\"-----------------------------------------------\")                \n",
    "        print(f\"{idx+1}. context to be fed into FM(e.g. Claude-v2)\")\n",
    "        print(\"-----------------------------------------------\")        \n",
    "        print_ww(context.page_content)        \n",
    "show_context_used(result['source_documents'])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# result['source_documents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "RAG(검색 증강 생성)에 관한 이 모듈을 완료한 것을 축하합니다! 이는 대규모 언어 모델의 성능과 검색 방법의 정확성을 결합하는 중요한 기술입니다. 검색된 관련 사례로 생성을 강화함으로써 우리가 받은 응답은 더욱 일관되고 일관되며 근거가 있게 됩니다. 당신은 이 혁신적인 접근 방식을 배우는 것에 자부심을 느껴야 합니다. 나는 당신이 얻은 지식이 창의적이고 매력적인 언어 생성 시스템을 구축하는 데 매우 유용할 것이라고 확신합니다. 잘하셨어요!\n",
    "\n",
    "위의 RAG 기반 질문 응답 구현에서 우리는 다음 개념과 Amazon Bedrock 및 LangChain 통합을 사용하여 이를 구현하는 방법을 탐색했습니다.\n",
    "\n",
    "- 문서 로드 및 임베딩 생성을 통해 벡터 저장소 생성\n",
    "- 질문에 대한 문서 검색\n",
    "- LLM에 대한 입력으로 사용되는 프롬프트 준비\n",
    "- 인간 친화적인 방식으로 답변 제시\n",
    "\n",
    "### Take-aways\n",
    "- 다양한 벡터 스토어를 실험해 보세요.\n",
    "- Amazon Bedrock에서 사용 가능한 다양한 모델을 활용하여 대체 출력을 확인하세요.\n",
    "- 임베딩 및 문서 청크의 영구 저장과 같은 옵션 탐색\n",
    "- 엔터프라이즈 데이터 저장소와의 통합\n",
    "\n",
    "# Thank You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
